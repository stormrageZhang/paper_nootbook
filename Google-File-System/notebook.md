Google File System
=====

## 一：简介（设计思路）
### 1.组件失效被认为是常态事件，而不是意外事件。  
    由于组件数量大，成本低，应用中失效的情况和原因都比较多，所以持续的监控、错误侦测、灾难冗余以及自动恢复的机制必须集成在GFS中。  
### 2.文件巨大。  
    在数据总体大小达到几百TB甚至更高的时候，管理数亿记的KB文件是不明智的，所以设计的假设条件和参数，比如 I/O 操作和 Block 的尺寸都需要重新考虑。  
### 3.绝大多数文件的修改选择从尾部追加数据，而不是覆盖原有数据。  
    对于这种针对海量文件的访问模式，客户端对数据块缓存是没有意义的，数据的追加操作是性能优化和原子性保证的主要考量因素。  
### 4.应用程序和文件系统API的协同设计提高了整体的灵活性。  
    放松了对一致性模型的要求，引入了原子性的记录追加操作，从而保证多个客户端能够同时进行追加操作，不需要额外的同步操作来保证数据的一致性。  

## 二：设计概述
### 1.设计预期
    （主要对设计思路的拓展） 
    1)系统必须持续监控自身的状态，它必须将组件失效作为一种常态，能够迅速地侦测、冗余并恢复失效的组件。  
    2)大文件和小文件并存，主要使得文件（大文件）得到有效的管理，系统必须支持小文件，但不必做专门的优化。  
    3)系统的主要负载表现在两种‘读’操作上，大规模的流式读取和小规模的随机读取。  
        大规模的流式读取往往大小在几百KB甚至1MB，来自一个客户机的连续操作通常是读取同一个文件中的连续的一个区域。  
        小规模通常是在文件某个随机的位置读取几个KB数据，如果应用系统对性能要求高，通常的做法是把小规模读取合并排序，避免在文件中反复移动读取位置。  
    4)系统的负载还包括许多大规模，顺序的，数据追加方式的写操作。写入数据的大小和大规模读类似，值得注意的是，一旦被写入，文件很少被修改。  
    5)系统必须是高效的，行为定义明确的实现多客户并行追加数据到同一个文件里的语义。使用最小的同步开销来实现原子的多路追加数据操作是必不可少的。  
    6)高性能的稳定网络宽带远比低延迟重要。  
### 2.接口
    GFS提供类似传统文件系统的一套API接口，但是不严格按照POSIX等标准。  
    文件以分层目录的形式组织，‘用路径名来表示’，支持：create，delete，open，close，write，read。  
    提供快照和记录追加操作，快照：低成本快速拷贝，记录追加操作：允许多个客户端同时对一个文件进行数据追加操作。这些对构建大型分布应用非常重要。  
### 3.架构
    一个GFS集群包含一个单独的Master节点，和多台Chunk服务器。  
    存储的文件被‘分割’为固定大小的块(Chunk)，Chunk被创建的时候，Master会给他一个不变的64位标示(Chunk handle)  
    Chunk服务器就以Linux文件的形式保存块(Chunk)在本地硬盘上。  
    出于可靠性(组件失效为常态)的考虑，每个块都会复制到多个Chunk服务器上，一般是三个。  
    Master节点管理的是文件系统的元数据：名字空间，访问控制信息，文件，Chunk的映射信息，Chunk的位置信息。Master周期的和每个Chunk服务器通信，发送指令，接受Chunk服务器的状态。  
    客户端和Master节点通信只获得元数据，所有数据的交互都是直接和Chunk服务器。  
    Chunk服务器不需要缓存文件，客户端也不需要，(因为大部分是以流的方式读取一个巨大文件)(但是会缓存Master给的元数据)  
### 4.单一Master节点
    单一Master节点可以简化设计，应做到减少对Master节点的读写。  
    流程：客户端把文件名和程序指定的字节便宜，根据固定的Chunk大小，转化成文件的Chunk索引，发送给Master节点，Master节点将相应的Chunk标识和副本位置发给客户端。  
    客户端用文件名和Chunk索引作为key缓存这些信息。当然一般客户端一次发送的请求查询多个Chunk信息，为的是避免客户端和Master节点未来可能会发送多次通信。  
### 5.Chunk(块)的尺寸
    Chunk的大小是关键的设计参数之一，google选择64MB，这个尺寸远大于一般文件系统的Block尺寸。  
    优点：1)减少客户端与Master节点的通讯需求，客户端可以轻松缓存数个TB工作数据集所有的Chunk位置信息。  
        2)客户端可以对一个Chunk进行多次操作，与Chunk保持较长时间的连接，减少网络负载。  
        3)较大的Chunk尺寸可以减少Master节点需要保存的元数据数量，元数据可以放在内存中。  
    缺点：小文件包含较少的Chunk，甚至只有一个，如果许多客户端对同一个小文件多次访问，存储这些Chunk的服务器就会成为热点。  
        google在批处理队列系统时，发生了由于一个可执行文件被数百客户端并发访问导致所在的Chunk服务器局部过载。  
        可以通过增加副本数量，避开批处理队列系统程序的启动时间来解决。  
### 6.元数据
    Master服务器存储‘3’种主要类型的元数据。  
        1)文件和Chunk的命名空间  
        2)文件和Chunk的对应关系  
        3)每个Chunk副本的存放地点  
    所有的元数据都存放在Master服务器的‘内存’中  
    前两种也会以记录变更日志的方式记录在操作系统的系统日志文件中，使得可以简单可靠的更新Master服务器的状态，并且不用担心服务器崩溃导致数据不一致的风险。  
    Master服务器不会持久保存Chunk位置信息，在启动，或者新Chunk服务器加入时，会向各个服务器询问Chunk信息。  
    Master服务器中元数据都保存在内存中，优点：操作快速，并且可以通过后台简单高效的周期性扫描自身保存的状态信息。  
    潜在问题：Chunk的数量增加，可能会超出内存极限。但事实中并不严重，64字节即可管理64MB的Chunk，文件的命名空间中数据通过’前缀压缩算法‘大致也在64字节内。  
    值得注意的是Master服务器是不保存持久化的Chunk的副本信息的，通过周期性的心跳信息监控Chunk服务器的状态。  
    这样的设计简单，高效，能解决各种Chunk服务器经常发生的状况(加入，离群，更名，失效，重启)  
    从另一个角度理解，只有Chunk服务器本身能确定一个Chunk是否在他的硬盘上。  

